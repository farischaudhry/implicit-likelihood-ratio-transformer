{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03c1901b",
   "metadata": {},
   "source": [
    "# Implicit Statistical Reasoning in Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7805d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import logging \n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "# Logging format: save logs to logs/ folder + console output\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('logs/experiment.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# Random seeds\n",
    "def set_seed(seed: int = 0):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(0)\n",
    "\n",
    "\n",
    "def set_plotting_style():\n",
    "    \"\"\"Sets up standard plotting style.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'text.usetex': False,\n",
    "        'font.family': 'serif',\n",
    "        'font.size': 12,\n",
    "        'axes.labelsize': 14,\n",
    "        'axes.titlesize': 16,\n",
    "        'xtick.labelsize': 11,\n",
    "        'ytick.labelsize': 11,\n",
    "        'legend.fontsize': 11,\n",
    "        'figure.figsize': (10, 7),\n",
    "        'axes.grid': True,\n",
    "        'grid.alpha': 0.3,\n",
    "        'lines.linewidth': 2.5,\n",
    "    })\n",
    "set_plotting_style()\n",
    "\n",
    "\n",
    "# PyTorch device selection\n",
    "DEVICE = torch.device(\n",
    "    'cuda' if torch.cuda.is_available() \n",
    "    else 'mps' if torch.backends.mps.is_available() \n",
    "    else 'cpu'\n",
    ")\n",
    "logging.info(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24272866",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"Controls the generation of synthetic tasks.\"\"\"\n",
    "    d: int = 16  # Input dimension\n",
    "    n_ctx: int = 32  # Number of context pairs\n",
    "    sigma_k: float = 3.0  # Task A: Shift magnitude\n",
    "    sigma_k_ood: float = 9.0  # Task A: OOD Shift magnitude\n",
    "    sigma_min: float = 0.5  # Task B: Variance lower bound\n",
    "    sigma_max: float = 3.0  # Task B: Variance upper bound\n",
    "    train_episodes: int = 50000  # Size of training dataset\n",
    "    val_episodes: int = 5000  # Size of validation dataset\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    \"\"\"Controls the optimization loop.\"\"\"\n",
    "    seeds: list[int] = field(default_factory=lambda: [0, 1, 2])\n",
    "    batch_size: int = 64\n",
    "    epochs: int = 20\n",
    "    lr: float = 3e-4\n",
    "    device: torch.device = DEVICE\n",
    "\n",
    "\n",
    "# Initialize Global Configs\n",
    "data_cfg = DataConfig()\n",
    "train_cfg = TrainConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39c67d8",
   "metadata": {},
   "source": [
    "## Sampling Tasks\n",
    "\n",
    "### Dataset Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_episode(\n",
    "    sample_task_params_fn: callable,\n",
    "    sample_data_fn: callable,\n",
    "    n_ctx: int,\n",
    "    d: int,\n",
    "    **task_kwargs\n",
    "):\n",
    "    \"\"\"Generic episode constructor.\"\"\"\n",
    "    task_params = sample_task_params_fn(d=d, **task_kwargs)\n",
    "\n",
    "    x_ctx, y_ctx = sample_data_fn(task_params, n_ctx, d)\n",
    "    x_q, y_q = sample_data_fn(task_params, 1, d)\n",
    "\n",
    "    return {\n",
    "        'context_x': x_ctx,\n",
    "        'context_y': y_ctx,\n",
    "        'query_x': x_q[0],\n",
    "        'query_y': y_q[0],\n",
    "        'task_params': task_params,\n",
    "    }\n",
    "\n",
    "\n",
    "class EpisodeDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for generating episodes on-the-fly.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        sample_task_params_fn,\n",
    "        sample_data_fn,\n",
    "        n_ctx: int,\n",
    "        d: int,\n",
    "        num_episodes: int,\n",
    "        device: torch.device = torch.device('cpu'),\n",
    "        **task_kwargs\n",
    "    ):\n",
    "        self.sample_task_params_fn = sample_task_params_fn\n",
    "        self.sample_data_fn = sample_data_fn\n",
    "        self.n_ctx = n_ctx\n",
    "        self.d = d\n",
    "        self.num_episodes = num_episodes\n",
    "        self.task_kwargs = dict(task_kwargs)\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_episodes\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Each batch from  yields:\n",
    "        {\n",
    "        'context_x': (B, n_ctx, d),\n",
    "        'context_y': (B, n_ctx),\n",
    "        'query_x':   (B, d),\n",
    "        'query_y':   (B,),\n",
    "        }\n",
    "        \"\"\"\n",
    "        episode = make_episode(\n",
    "            sample_task_params_fn=self.sample_task_params_fn,\n",
    "            sample_data_fn=self.sample_data_fn,\n",
    "            n_ctx=self.n_ctx,\n",
    "            d=self.d,\n",
    "            **self.task_kwargs\n",
    "        )\n",
    "\n",
    "        # Convert to torch tensors where appropriate\n",
    "        return {\n",
    "            'context_x': torch.as_tensor(episode['context_x'], dtype=torch.float32, device=self.device),\n",
    "            'context_y': torch.as_tensor(episode['context_y'], dtype=torch.long, device=self.device),\n",
    "            'query_x': torch.as_tensor(episode['query_x'], dtype=torch.float32, device=self.device),\n",
    "            'query_y': torch.as_tensor(episode['query_y'], dtype=torch.float32, device=self.device),\n",
    "            'task_params': episode['task_params'],  # keep as Python object\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cddecb5",
   "metadata": {},
   "source": [
    "### Task A: Shifted Mean Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_task_A_params(d: int, sigma_k: float) -> dict:\n",
    "    \"\"\"\n",
    "    Samples task parameters for Task A: Mean Discrimination.\n",
    "\n",
    "    Arguments:\n",
    "    d: data dimension\n",
    "    sigma_k: standard deviation of the shift, k\n",
    "\n",
    "    Returns (mu, k).\n",
    "    \"\"\"\n",
    "    mu = np.random.randn(d)\n",
    "    mu /= np.linalg.norm(mu) \n",
    "\n",
    "    k = np.random.randn(d) * sigma_k\n",
    "    return {'mu': mu, 'k': k}\n",
    "\n",
    "\n",
    "def sample_task_A_data(task_params: dict, n: int, d: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Samples labeled data from mean discrimination task.\n",
    "    Returns {x, y}_1^n with y in {0,1}.\n",
    "    \"\"\"\n",
    "    mu, k = task_params['mu'], task_params['k']\n",
    "    y = np.random.randint(0, 2, size=n)\n",
    "    means = np.where(y[:, None] == 1, mu + k, -mu + k)\n",
    "    x = means + np.random.randn(n, d)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def task_A_llr(x: np.ndarray, mu: np.ndarray, k: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bayes-optimal log-likelihood ratio for mean discrimination.\n",
    "    \"\"\"\n",
    "    centered_x = x - k\n",
    "    dot_prod = (mu * centered_x).sum(axis=1)\n",
    "    return 2 * dot_prod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f4fd0",
   "metadata": {},
   "source": [
    "### Task B: Variance Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec298962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_task_B_params(d: int, sigma_min: float = 0.5, sigma_max: float = 3.0) -> dict:\n",
    "    \"\"\"\n",
    "    Samples variances (sigma_0, sigma_1) from uniform distributions.\n",
    "    \"\"\"\n",
    "    sigma_0 = np.random.uniform(sigma_min, sigma_max)\n",
    "    sigma_1 = np.random.uniform(sigma_min, sigma_max)\n",
    "    return {'sigma_0': sigma_0, 'sigma_1': sigma_1}\n",
    "\n",
    "\n",
    "def sample_task_B_data(task_params: dict, n: int, d: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Samples labeled data from variance discrimination task.\n",
    "    \"\"\"\n",
    "    sigma_0 = task_params['sigma_0']\n",
    "    sigma_1 = task_params['sigma_1']\n",
    "\n",
    "    y = np.random.randint(0, 2, size=n)\n",
    "    sigmas = np.where(y == 1, sigma_1, sigma_0)\n",
    "\n",
    "    x = np.random.randn(n, d) * sigmas[:, None]\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def task_B_llr(x: np.ndarray, sigma_0: float, sigma_1: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bayes-optimal log-likelihood ratio for variance discrimination.\n",
    "    \"\"\"\n",
    "    d = x.shape[1]\n",
    "    # Compute Norm Squared ||x||^2\n",
    "    norm_sq = (x**2).sum(axis=1)\n",
    "    # Compute Constant Bias term\n",
    "    # (d/2) * ln(sigma_0^2 / sigma_1^2)\n",
    "    # simplifes to d * ln(sigma_0 / sigma_1)\n",
    "    bias = d * np.log(sigma_0 / sigma_1)\n",
    "    # Compute Quadratic Term\n",
    "    # coeff = 0.5 * (1/sigma_0^2 - 1/sigma_1^2)\n",
    "    coeff = 0.5 * ((1.0 / sigma_0**2) - (1.0 / sigma_1**2))\n",
    "    return bias + (coeff * norm_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9636bd7f",
   "metadata": {},
   "source": [
    "### Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea24e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "train_loader_A_no_nuisance = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_A_params,\n",
    "        sample_data_fn=sample_task_A_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.train_episodes,\n",
    "        sigma_k=0.0,  # No nuisance shift\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader_A_no_nuisance = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_A_params,\n",
    "        sample_data_fn=sample_task_A_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.val_episodes,\n",
    "        sigma_k=0.0,  # No nuisance shift\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "train_loader_A = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_A_params,\n",
    "        sample_data_fn=sample_task_A_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.train_episodes,\n",
    "        sigma_k=data_cfg.sigma_k,\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader_A = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_A_params,\n",
    "        sample_data_fn=sample_task_A_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.val_episodes,\n",
    "        sigma_k=data_cfg.sigma_k,\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "val_loader_A_OOD = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_A_params,\n",
    "        sample_data_fn=sample_task_A_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.val_episodes,\n",
    "        sigma_k=data_cfg.sigma_k_ood,  # OOD nuisance variables\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "train_loader_B = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_B_params,\n",
    "        sample_data_fn=sample_task_B_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.train_episodes,\n",
    "        sigma_min=data_cfg.sigma_min,\n",
    "        sigma_max=data_cfg.sigma_max,\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader_B = DataLoader(\n",
    "    EpisodeDataset(\n",
    "        sample_task_params_fn=sample_task_B_params,\n",
    "        sample_data_fn=sample_task_B_data,\n",
    "        n_ctx=data_cfg.n_ctx,\n",
    "        d=data_cfg.d,\n",
    "        num_episodes=data_cfg.val_episodes,\n",
    "        sigma_min=data_cfg.sigma_min,\n",
    "        sigma_max=data_cfg.sigma_max,\n",
    "        device=train_cfg.device\n",
    "    ),\n",
    "    batch_size=train_cfg.batch_size, shuffle=False, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e132f22",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea053c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: nn.Module, batch: dict, optimizer: optim.Optimizer, loss_fn: nn.Module, scheduler: optim.lr_scheduler._LRScheduler = None):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits = model(\n",
    "        context_x=batch['context_x'],\n",
    "        context_y=batch['context_y'],\n",
    "        query_x=batch['query_x'],\n",
    "    )\n",
    "\n",
    "    target = batch['query_y'].float().view(-1, 1) \n",
    "    loss = loss_fn(logits, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > 0.5).float()\n",
    "        acc = (preds == target).float().mean().item()\n",
    "\n",
    "    return loss.item(), acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_step(model: nn.Module, batch: dict, loss_fn: nn.Module):\n",
    "    model.eval()\n",
    "\n",
    "    logits = model(\n",
    "        context_x=batch['context_x'],\n",
    "        context_y=batch['context_y'],\n",
    "        query_x=batch['query_x'],\n",
    "    )\n",
    "\n",
    "    target = batch['query_y'].float().view(-1, 1)\n",
    "    loss = loss_fn(logits, target)\n",
    "    \n",
    "    probs = torch.sigmoid(logits)\n",
    "    preds = (probs > 0.5).float()\n",
    "    acc = (preds == target).float().mean().item()\n",
    "\n",
    "    return loss.item(), acc, logits.cpu(), target.cpu()\n",
    "\n",
    "\n",
    "def run_epoch(\n",
    "        model: nn.Module, dataloader: DataLoader, optimizer: optim.Optimizer = None, scheduler: optim.lr_scheduler._LRScheduler = None\n",
    "    ) -> dict:\n",
    "    is_train = optimizer is not None\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_logits, all_labels = [], []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        if is_train:\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_fn, scheduler)\n",
    "            logits = None\n",
    "            labels = None\n",
    "        else:\n",
    "            loss, acc, logits, labels = eval_step(model, batch, loss_fn)\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "        B = batch['query_y'].numel()\n",
    "        total_loss += loss * B\n",
    "        correct += int(acc * B)\n",
    "        total += B\n",
    "\n",
    "    metrics = {\n",
    "        'loss': total_loss / total,\n",
    "        'acc': correct / total,\n",
    "    }\n",
    "\n",
    "    if not is_train:\n",
    "        metrics['logits'] = torch.cat(all_logits)\n",
    "        metrics['labels'] = torch.cat(all_labels)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    save_best: bool = False,\n",
    ") -> tuple[list[dict], dict | None]:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, \n",
    "        max_lr=lr, \n",
    "        epochs=epochs, \n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.3,  # Warmup for 30% of time\n",
    "    )\n",
    "\n",
    "    history = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_metrics = run_epoch(model, train_loader, optimizer, scheduler)\n",
    "        val_metrics = run_epoch(model, val_loader)\n",
    "\n",
    "        # Store metrics for this epoch\n",
    "        history.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'train_acc': train_metrics['acc'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_acc': val_metrics['acc']\n",
    "        })\n",
    "\n",
    "        if save_best and val_metrics['loss'] < best_val_loss:\n",
    "            best_val_loss = val_metrics['loss']\n",
    "            best_state = {\n",
    "                k: v.detach().cpu()\n",
    "                for k, v in model.state_dict().items()\n",
    "            }\n",
    "\n",
    "        logging.info(\n",
    "            f\"[Epoch {epoch:03d}] \"\n",
    "            f\"Train loss={train_metrics['loss']:.4f}, acc={train_metrics['acc']:.3f} | \"\n",
    "            f\"Val loss={val_metrics['loss']:.4f}, acc={val_metrics['acc']:.3f}\"\n",
    "        )\n",
    "\n",
    "    return history, best_state\n",
    "\n",
    "\n",
    "def run_multiseed_experiment(\n",
    "    model_class: type[nn.Module],\n",
    "    model_kwargs: dict,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    seeds: list[int] | None,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    device: torch.device = torch.device('cpu'),\n",
    "    experiment_name: str = 'task',\n",
    "    checkpoint_dir: str | Path = 'checkpoints',\n",
    "    data_output_dir: str | Path = 'results',\n",
    ") -> pd.DataFrame:\n",
    "    if seeds is None:\n",
    "        seeds = [0, 1, 2]\n",
    "\n",
    "    checkpoint_dir = Path(checkpoint_dir)\n",
    "    data_output_dir = Path(data_output_dir)\n",
    "\n",
    "    all_results = []\n",
    "    model_name = model_class.__name__\n",
    "\n",
    "    logging.info(f'Running experiment for model: {model_name} with seeds: {seeds}')\n",
    "    \n",
    "    for seed in seeds:\n",
    "        logging.info(f'Starting training with seed: {seed}')\n",
    "        set_seed(seed)\n",
    "\n",
    "        # Re-initialize Model Fresh \n",
    "        model = model_class(**model_kwargs).to(device)\n",
    "        history, best_state = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            epochs=epochs,\n",
    "            lr=lr,\n",
    "            save_best=True,\n",
    "        )\n",
    "\n",
    "        # Save best model checkpoint\n",
    "        ckpt_path = checkpoint_dir / experiment_name / f'{model_name}_seed{seed}.pt'\n",
    "        os.makedirs(ckpt_path.parent, exist_ok=True)\n",
    "        torch.save({\n",
    "            'model_class': model_name,\n",
    "            'model_kwargs': model_kwargs,\n",
    "            'seed': seed,\n",
    "            'best_state_dict': best_state,\n",
    "        }, ckpt_path)\n",
    "        logging.info(f'Saved checkpoint to {ckpt_path}')\n",
    "\n",
    "        # Add metadata and store\n",
    "        for epoch_data in history:\n",
    "            epoch_data.update({\n",
    "                'seed': seed,\n",
    "                'model': model_name,\n",
    "                'experiment': experiment_name,\n",
    "            })\n",
    "            all_results.append(epoch_data)\n",
    "\n",
    "    # Restore global seed\n",
    "    set_seed(0) \n",
    "\n",
    "    df = pd.DataFrame(all_results)\n",
    "    # Save results to CSV\n",
    "    data_output_dir = Path(data_output_dir)\n",
    "    data_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = data_output_dir / experiment_name / f'{model_name}_results.csv'\n",
    "    os.makedirs(csv_path.parent, exist_ok=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    logging.info(f'Saved results to {csv_path}')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b2afc",
   "metadata": {},
   "source": [
    "## Main Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad361953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLTransformer(nn.Module):\n",
    "    def __init__(self, d_in, n_ctx, d_model=128, n_layers=2, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_ctx = n_ctx\n",
    "        # Embeddings\n",
    "        self.x_proj = nn.Linear(d_in, d_model)\n",
    "        self.y_proj = nn.Linear(1, d_model)\n",
    "        self.query_proj = nn.Linear(d_in, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, n_ctx + 1, d_model) * 0.02)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=n_heads, \n",
    "            dim_feedforward=4*d_model, \n",
    "            dropout=0.0, # No dropout for synthetic tasks required\n",
    "            batch_first=True,\n",
    "            activation='gelu',\n",
    "            norm_first=False,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        B = context_x.shape[0]\n",
    "        N = context_x.shape[1]\n",
    "        # Embed Context: Combine x and y\n",
    "        ctx_emb = self.x_proj(context_x) + self.y_proj(context_y.unsqueeze(-1).float())\n",
    "        # Embed Query: It has no y, so we just embed x\n",
    "        q_emb = self.query_proj(query_x).unsqueeze(1) # [B, 1, D]\n",
    "        # Concatenate: [Ctx_1, ..., Ctx_N, Query]\n",
    "        seq = torch.cat([ctx_emb, q_emb], dim=1) # [B, N+1, D]\n",
    "        # Add Positional Embeddings\n",
    "        seq = seq + self.pos_emb[:, :seq.shape[1], :]\n",
    "        # Transformer Pass\n",
    "        out = self.transformer(seq)\n",
    "        # Predict only on the Query token (the last one)\n",
    "        query_out = out[:, -1, :]\n",
    "        logits = self.head(query_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b73448",
   "metadata": {},
   "source": [
    "## PART I: Recovery of Optimal Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f0a954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Experiment: Task A (In sample validation)\n",
    "# run_multiseed_experiment(\n",
    "#     model_class=ICLTransformer,\n",
    "#     model_kwargs={\n",
    "#         'd_in': data_cfg.d,\n",
    "#         'n_ctx': data_cfg.n_ctx,\n",
    "#         'd_model': 128,\n",
    "#         'n_layers': 2,\n",
    "#         'n_heads': 4,\n",
    "#     },\n",
    "#     train_loader=train_loader_A,\n",
    "#     val_loader=val_loader_A,\n",
    "#     seeds=train_cfg.seeds,\n",
    "#     epochs=train_cfg.epochs,\n",
    "#     lr=train_cfg.lr,\n",
    "#     device=train_cfg.device,\n",
    "#     experiment_name='task_A_regular',\n",
    "#     checkpoint_dir='checkpoints',\n",
    "#     data_output_dir='results',\n",
    "# )\n",
    "\n",
    "# # Experiment: Task A (OOD validation)\n",
    "# run_multiseed_experiment(\n",
    "#     model_class=ICLTransformer,\n",
    "#     model_kwargs={\n",
    "#         'd_in': data_cfg.d,\n",
    "#         'n_ctx': data_cfg.n_ctx,\n",
    "#         'd_model': 128,\n",
    "#         'n_layers': 2,\n",
    "#         'n_heads': 4,\n",
    "#     },\n",
    "#     train_loader=train_loader_A,\n",
    "#     val_loader=val_loader_A_OOD,\n",
    "#     seeds=train_cfg.seeds,\n",
    "#     epochs=train_cfg.epochs,\n",
    "#     lr=train_cfg.lr,\n",
    "#     device=train_cfg.device,\n",
    "#     experiment_name='task_A_OOD',\n",
    "#     checkpoint_dir='checkpoints',\n",
    "#     data_output_dir='results',\n",
    "# )\n",
    "\n",
    "# # Experiment: Task B\n",
    "# run_multiseed_experiment(\n",
    "#     model_class=ICLTransformer,\n",
    "#     model_kwargs={\n",
    "#         'd_in': data_cfg.d,\n",
    "#         'n_ctx': data_cfg.n_ctx,\n",
    "#         'd_model': 128,\n",
    "#         'n_layers': 2,\n",
    "#         'n_heads': 4,\n",
    "#     },\n",
    "#     train_loader=train_loader_B,\n",
    "#     val_loader=val_loader_B,\n",
    "#     seeds=train_cfg.seeds,\n",
    "#     epochs=train_cfg.epochs,\n",
    "#     lr=train_cfg.lr,\n",
    "#     device=train_cfg.device,\n",
    "#     experiment_name='task_B_regular',\n",
    "#     checkpoint_dir='checkpoints',\n",
    "#     data_output_dir='results',\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846689ab",
   "metadata": {},
   "source": [
    "## PART II: Failure Modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6cb25",
   "metadata": {},
   "source": [
    "### Model Ablation Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07671379",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ICLTransformerInterleavedEmbeddings(nn.Module):\n",
    "    \"\"\" \n",
    "    Context provided as (x, y) pairs interleaved in sequence.\n",
    "    Tests the inductive bias of using (x, y) together, which is broken by interleaving.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, n_ctx, d_model=128, n_layers=2, n_heads=4, max_len=512):\n",
    "        assert max_len >= 2 * n_ctx + 1, 'max_len must be at least 2*n_ctx + 1'\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Embeddings\n",
    "        # Projects input data x -> d_model\n",
    "        self.x_embed = nn.Linear(d_in, d_model)\n",
    "        # Embeds binary labels y -> d_model\n",
    "        self.y_embed = nn.Embedding(2, d_model)\n",
    "        # Learned positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, max_len, d_model) * 0.02)\n",
    "        \n",
    "        # Transformer Encoder (GPT-style)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=n_heads, \n",
    "            dim_feedforward=4*d_model, \n",
    "            dropout=0.0, # No dropout for synthetic tasks required\n",
    "            batch_first=True,\n",
    "            activation='gelu',\n",
    "            norm_first=False,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            context_x: (B, N, d)\n",
    "            context_y: (B, N)\n",
    "            query_x:   (B, d)\n",
    "        \"\"\"\n",
    "        B, N, _ = context_x.shape\n",
    "        device = context_x.device\n",
    "        # Embed inputs \n",
    "        ctx_x_emb = self.x_embed(context_x)  # (B, N, d_model)\n",
    "        qry_x_emb = self.x_embed(query_x.unsqueeze(1))  # (B, 1, d_model)\n",
    "        ctx_y_emb = self.y_embed(context_y)  # (B, N, d_model)\n",
    "        # Interleave Sequence \n",
    "        # Sequence: [x1, y1, x2, y2, ..., xN, yN, x_query]\n",
    "        # Total length = 2*N + 1\n",
    "        seq_len = 2*N + 1\n",
    "        seq_emb = torch.zeros(B, seq_len, self.d_model, device=device)\n",
    "        # Evens are X, Odds are Y\n",
    "        seq_emb[:, 0:2*N:2, :] = ctx_x_emb\n",
    "        seq_emb[:, 1:2*N:2, :] = ctx_y_emb\n",
    "        # Last token is Query X\n",
    "        seq_emb[:, -1, :] = qry_x_emb.squeeze(1)\n",
    "        # Add Position & Forward\n",
    "        seq_emb = seq_emb + self.pos_embed[:, :seq_len, :]\n",
    "        out = self.transformer(seq_emb)\n",
    "        # Predict on last token (repr of x_query)\n",
    "        last_token = out[:, -1, :]\n",
    "        return self.head(last_token)\n",
    "    \n",
    "\n",
    "class ICLTransformerNoLabels(nn.Module):\n",
    "    \"\"\"\n",
    "    Context provided, but labels y are removed.\n",
    "    Tests whether performance relies on (x, y) pairing.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, n_ctx, d_model=128, n_layers=2, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.x_proj = nn.Linear(d_in, d_model)\n",
    "        self.query_proj = nn.Linear(d_in, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, n_ctx + 1, d_model) * 0.02)\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=4*d_model,\n",
    "            dropout=0.0,\n",
    "            batch_first=True,\n",
    "            activation='gelu',\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)\n",
    "        self.head = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        ctx_emb = self.x_proj(context_x)\n",
    "        q_emb = self.query_proj(query_x).unsqueeze(1)\n",
    "        seq = torch.cat([ctx_emb, q_emb], dim=1)\n",
    "        seq = seq + self.pos_emb[:, :seq.shape[1], :]\n",
    "        out = self.transformer(seq)\n",
    "        return self.head(out[:, -1])\n",
    "\n",
    "\n",
    "class ICLTransformerShuffledLabels(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Labels y are randomly permuted within each batch.\n",
    "    Preserves label distribution but breaks x-y association.\n",
    "    \"\"\"\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        B, N = context_y.shape\n",
    "        perm = torch.randperm(N, device=context_y.device)\n",
    "        shuffled_y = context_y[:, perm]\n",
    "        return super().forward(context_x, shuffled_y, query_x)\n",
    "\n",
    "\n",
    "class ICLTransformerShuffledContext(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Context (x, y) pairs are randomly permuted within each batch.\n",
    "    Tests whether the model relies on the order of context points.\n",
    "    \"\"\"\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        B, N, _ = context_x.shape\n",
    "        perm = torch.randperm(N, device=context_x.device)\n",
    "        return super().forward(\n",
    "            context_x[:, perm],\n",
    "            context_y[:, perm],\n",
    "            query_x\n",
    "        )\n",
    "    \n",
    "\n",
    "class ICLTransformerFrozenAttention(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Attention weights are frozen at initialization.\n",
    "    Only value projections + MLPs train.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        for layer in self.transformer.layers:\n",
    "            attn = layer.self_attn\n",
    "\n",
    "            # Freeze Q, K, V projections\n",
    "            for p in attn.in_proj_weight, attn.in_proj_bias:\n",
    "                if p is not None:\n",
    "                    p.requires_grad = False\n",
    "\n",
    "            # Freeze output projection\n",
    "            attn.out_proj.weight.requires_grad = False\n",
    "            attn.out_proj.bias.requires_grad = False\n",
    "\n",
    "\n",
    "class ICLTransformerFrozenQK(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Query and key projections frozen; values trainable.\n",
    "    Tests whether matching is essential or only aggregation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        for layer in self.transformer.layers:\n",
    "            attn = layer.self_attn\n",
    "            d = attn.embed_dim\n",
    "            \n",
    "            # We define a hook that zeroes out the gradients for the first 2*d rows\n",
    "            # (which correspond to Q and K in the fused in_proj_weight)\n",
    "            def get_qk_freeze_hook(d_dim):\n",
    "                def hook(grad):\n",
    "                    # grad shape is (3*d, d) for weight, (3*d) for bias\n",
    "                    # We clone to ensure we don't modify the gradient buffer in place unexpectedly\n",
    "                    new_grad = grad.clone()\n",
    "                    # Zero out Q and K parts\n",
    "                    new_grad[:2*d_dim] = 0.0\n",
    "                    return new_grad\n",
    "                return hook\n",
    "\n",
    "            # Register the hook on the parameters\n",
    "            attn.in_proj_weight.register_hook(get_qk_freeze_hook(d))\n",
    "            \n",
    "            if attn.in_proj_bias is not None:\n",
    "                attn.in_proj_bias.register_hook(get_qk_freeze_hook(d))\n",
    "\n",
    "\n",
    "class ICLTransformerFrozenPos(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Positional embeddings are frozen at initialization.\n",
    "    Tests reliance on learned absolute position.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pos_emb.requires_grad = False\n",
    "\n",
    "\n",
    "class ICLTransformerNoPos(ICLTransformer):\n",
    "    \"\"\"\n",
    "    No positional information at all.\n",
    "    Tests permutation-invariant aggregation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        with torch.no_grad():\n",
    "            self.pos_emb.zero_()\n",
    "        self.pos_emb.requires_grad = False\n",
    "\n",
    "\n",
    "class ICLTransformerNoisyLabels(ICLTransformer):\n",
    "    \"\"\"\n",
    "    Injects random label noise during forward pass.\n",
    "    Tests robustness of evidence aggregation.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, noise_p=0.2, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.noise_p = noise_p\n",
    "\n",
    "    def forward(self, context_x, context_y, query_x):\n",
    "        if self.training and self.noise_p > 0:\n",
    "            noise = torch.rand_like(context_y.float()) < self.noise_p\n",
    "            context_y = context_y.clone()\n",
    "            context_y[noise] = 1 - context_y[noise]\n",
    "        return super().forward(context_x, context_y, query_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8032a4a",
   "metadata": {},
   "source": [
    "### Ablation Runs on Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ABLATIONS_TASK_A = [\n",
    "#     ('interleaved', ICLTransformerInterleavedEmbeddings, {}),\n",
    "#     ('no_labels', ICLTransformerNoLabels, {}),\n",
    "#     ('shuffled_labels', ICLTransformerShuffledLabels, {}),\n",
    "#     ('shuffled_context', ICLTransformerShuffledContext, {}),\n",
    "#     ('frozen_attention', ICLTransformerFrozenAttention, {}),\n",
    "#     ('frozen_qk', ICLTransformerFrozenQK, {}),\n",
    "#     ('frozen_pos', ICLTransformerFrozenPos, {}),\n",
    "#     ('no_pos', ICLTransformerNoPos, {}),\n",
    "# ]\n",
    "# for ablation_name, model_class, model_kwargs in ABLATIONS_TASK_A:\n",
    "#     run_multiseed_experiment(\n",
    "#         model_class=model_class,\n",
    "#         model_kwargs={\n",
    "#             'd_in': data_cfg.d,\n",
    "#             'n_ctx': data_cfg.n_ctx,\n",
    "#             'd_model': 128,\n",
    "#             'n_layers': 2,\n",
    "#             'n_heads': 4,\n",
    "#             **model_kwargs,\n",
    "#         },\n",
    "#         train_loader=train_loader_A,\n",
    "#         val_loader=val_loader_A,\n",
    "#         seeds=train_cfg.seeds,\n",
    "#         epochs=train_cfg.epochs,\n",
    "#         lr=train_cfg.lr,\n",
    "#         device=train_cfg.device,\n",
    "#         experiment_name=f'task_A_ablation_{ablation_name}',\n",
    "#         checkpoint_dir='checkpoints',\n",
    "#         data_output_dir='results',\n",
    "#     )\n",
    "\n",
    "\n",
    "# run_multiseed_experiment(\n",
    "#     model_class=ICLTransformer,\n",
    "#     model_kwargs={\n",
    "#         'd_in': data_cfg.d,\n",
    "#         'n_ctx': 2 * data_cfg.n_ctx,\n",
    "#         'd_model': 128,\n",
    "#         'n_layers': 2,\n",
    "#         'n_heads': 4,\n",
    "#     },\n",
    "#     train_loader=train_loader_A,\n",
    "#     val_loader=val_loader_A,\n",
    "#     seeds=train_cfg.seeds,\n",
    "#     epochs=train_cfg.epochs,\n",
    "#     lr=train_cfg.lr,\n",
    "#     device=train_cfg.device,\n",
    "#     experiment_name='task_A_ablation_context_increase',\n",
    "#     checkpoint_dir='checkpoints',\n",
    "#     data_output_dir='results',\n",
    "# )\n",
    "\n",
    "\n",
    "# NOISE_LEVELS = [0.1, 0.2, 0.4]\n",
    "# for p in NOISE_LEVELS:\n",
    "#     run_multiseed_experiment(\n",
    "#         model_class=ICLTransformerNoisyLabels,\n",
    "#         model_kwargs={\n",
    "#             'd_in': data_cfg.d,\n",
    "#             'n_ctx': data_cfg.n_ctx,\n",
    "#             'd_model': 128,\n",
    "#             'n_layers': 2,\n",
    "#             'n_heads': 4,\n",
    "#             'noise_p': p,\n",
    "#         },\n",
    "#         train_loader=train_loader_A,\n",
    "#         val_loader=val_loader_A,\n",
    "#         seeds=train_cfg.seeds,\n",
    "#         epochs=train_cfg.epochs,\n",
    "#         lr=train_cfg.lr,\n",
    "#         device=train_cfg.device,\n",
    "#         experiment_name=f'task_A_ablation_noisy_labels_p{p}',\n",
    "#         checkpoint_dir='checkpoints',\n",
    "#         data_output_dir='results',\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da1c32",
   "metadata": {},
   "source": [
    "## Analysis of Part I and II\n",
    "\n",
    "### Summary Statistics and History Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_results_csvs(results_root='results') -> pd.DataFrame:\n",
    "    paths = sorted(glob.glob(os.path.join(results_root, '**', '*.csv'), recursive=True))\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "        except Exception as e:\n",
    "            logging.info(f'[WARN] failed to read {p}: {e}')\n",
    "            continue\n",
    "\n",
    "        df['source_path'] = p\n",
    "\n",
    "        if 'experiment' not in df.columns:\n",
    "            df['experiment'] = os.path.basename(os.path.dirname(p))\n",
    "\n",
    "        if 'seed' in df.columns:\n",
    "            df['seed'] = df['seed'].astype(int)\n",
    "        if 'epoch' in df.columns:\n",
    "            df['epoch'] = df['epoch'].astype(int)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        raise RuntimeError(f'No CSVs found under: {results_root}')\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "def mean_ci95_halfwidth(x: pd.Series):\n",
    "    x = x.dropna().to_numpy(dtype=float)\n",
    "    n = len(x)\n",
    "    if n == 0:\n",
    "        return np.nan, np.nan, 0\n",
    "    mean = float(np.mean(x))\n",
    "    if n == 1:\n",
    "        return mean, np.nan, 1\n",
    "    sd = float(np.std(x, ddof=1))\n",
    "    half = 1.96 * sd / math.sqrt(n)\n",
    "    return mean, half, n\n",
    "\n",
    "\n",
    "def final_train_val_table(df_all: pd.DataFrame):\n",
    "    required = {'experiment', 'model', 'seed', 'epoch', 'train_acc', 'val_acc'}\n",
    "    missing = required - set(df_all.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing required columns: {missing}')\n",
    "\n",
    "    last_rows = (\n",
    "        df_all.sort_values(['experiment', 'model', 'seed', 'epoch'])\n",
    "              .groupby(['experiment', 'model', 'seed'], as_index=False)\n",
    "              .tail(1)\n",
    "    )\n",
    "\n",
    "    out = []\n",
    "    for (exp, model), g in last_rows.groupby(['experiment', 'model']):\n",
    "        tr_m, tr_h, n1 = mean_ci95_halfwidth(g['train_acc'])\n",
    "        va_m, va_h, n2 = mean_ci95_halfwidth(g['val_acc'])\n",
    "        n = min(n1, n2)\n",
    "\n",
    "        out.append({\n",
    "            'experiment': exp,\n",
    "            'model': model,\n",
    "            'n_seeds': n,\n",
    "            'train_acc_ci95': (f'{tr_m:.4f} ± {tr_h:.4f}' if not np.isnan(tr_h) else f'{tr_m:.4f}'),\n",
    "            'val_acc_ci95':   (f'{va_m:.4f} ± {va_h:.4f}' if not np.isnan(va_h) else f'{va_m:.4f}'),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(out).sort_values(['experiment', 'model']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def plot_learning_curves_ci95(\n",
    "    df_all: pd.DataFrame,\n",
    "    experiment: str,\n",
    "    model: str | None = None,\n",
    "    out_path: str | None = None,\n",
    "):\n",
    "    required = {'experiment', 'epoch', 'seed', 'train_acc', 'val_acc'}\n",
    "    missing = required - set(df_all.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing required columns: {missing}')\n",
    "\n",
    "    df = df_all[df_all['experiment'] == experiment].copy()\n",
    "    if model is not None:\n",
    "        if 'model' not in df.columns:\n",
    "            raise ValueError('model column missing; cannot filter by model.')\n",
    "        df = df[df['model'] == model].copy()\n",
    "    if df.empty:\n",
    "        raise ValueError(f'No rows found for experiment={experiment} model={model}')\n",
    "\n",
    "    def agg_mean_ci(x):  # 95% CI \n",
    "        x = x.dropna().to_numpy(dtype=float)\n",
    "        n = len(x)\n",
    "        m = float(np.mean(x)) if n else np.nan\n",
    "        if n <= 1:\n",
    "            return pd.Series({'mean': m, 'ci': np.nan})\n",
    "        sd = float(np.std(x, ddof=1))\n",
    "        ci = 1.96 * sd / math.sqrt(n)\n",
    "        return pd.Series({'mean': m, 'ci': ci})\n",
    "    \n",
    "    train_stats = df.groupby('epoch')['train_acc'].apply(agg_mean_ci).reset_index()\n",
    "    val_stats = df.groupby('epoch')['val_acc'].apply(agg_mean_ci).reset_index()\n",
    "\n",
    "    # flatten output \n",
    "    train_stats = train_stats.pivot(index='epoch', columns='level_1', values='train_acc').reset_index()\n",
    "    val_stats = val_stats.pivot(index='epoch', columns='level_1', values='val_acc').reset_index()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_stats['epoch'], train_stats['mean'], label='Train Accuracy')\n",
    "    plt.fill_between(\n",
    "        train_stats['epoch'],\n",
    "        train_stats['mean'] - train_stats['ci'].fillna(0),\n",
    "        train_stats['mean'] + train_stats['ci'].fillna(0),\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    plt.plot(val_stats['epoch'], val_stats['mean'], label='Validation Accuracy')\n",
    "    plt.fill_between(\n",
    "        val_stats['epoch'],\n",
    "        val_stats['mean'] - val_stats['ci'].fillna(0),\n",
    "        val_stats['mean'] + val_stats['ci'].fillna(0),\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    clean_experiment_name = experiment.replace('_', ' ').title()\n",
    "    title = f'{clean_experiment_name}' + (f' | {model}' if model is not None else '')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.0, 1.0)\n",
    "    plt.legend()\n",
    "\n",
    "    if out_path is not None:\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        plt.savefig(out_path, dpi=200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f'Saved plot to: {out_path}')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = load_all_results_csvs('results')\n",
    "summary = final_train_val_table(df_all)\n",
    "logging.info(summary.to_string(index=False))\n",
    "os.makedirs('analysis_out', exist_ok=True)\n",
    "summary.to_csv('analysis_out/final_train_val_acc_ci95.csv', index=False)\n",
    "logging.info('Saved summary to analysis_out/final_train_val_acc_ci95.csv')\n",
    "\n",
    "experiments = df_all['experiment'].unique()\n",
    "models = df_all['model'].unique()\n",
    "for exp in experiments:\n",
    "    for mod in models:\n",
    "        try:\n",
    "            plot_learning_curves_ci95(\n",
    "                df_all,\n",
    "                experiment=exp,\n",
    "                model=mod,\n",
    "                out_path=f'analysis_out/{exp}_{mod}_learning_curve_ci95.png',\n",
    "            )\n",
    "        except ValueError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a228ef",
   "metadata": {},
   "source": [
    "### Logit vs LLR Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_checkpoint(ckpt_path, device: torch.device = DEVICE) -> nn.Module:\n",
    "    checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "    \n",
    "    # Get the class name and arguments\n",
    "    class_name = checkpoint['model_class']\n",
    "    kwargs = checkpoint['model_kwargs']\n",
    "    state_dict = checkpoint['best_state_dict']\n",
    "    \n",
    "    logging.info(f'Loading {class_name} from seed {checkpoint[\"seed\"]} from {ckpt_path}')\n",
    "    \n",
    "    # Map string name to actual Class object\n",
    "    MODEL_MAP = {\n",
    "        'ICLTransformer': ICLTransformer,\n",
    "        'ICLTransformerNoLabels': ICLTransformerNoLabels,\n",
    "        'ICLTransformerFrozenPos': ICLTransformerFrozenPos,\n",
    "        'ICLTransformerNoPos': ICLTransformerNoPos,\n",
    "        'ICLTransformerFrozenQK': ICLTransformerFrozenQK,\n",
    "        'ICLTransformerShuffledLabels': ICLTransformerShuffledLabels,\n",
    "        'ICLTransformerShuffledContext': ICLTransformerShuffledContext,\n",
    "        'ICLTransformerNoisyLabels': ICLTransformerNoisyLabels,\n",
    "    }\n",
    "    \n",
    "    if class_name not in MODEL_MAP:\n",
    "        raise ValueError(f'Unknown model class: {class_name}')\n",
    "    \n",
    "    ModelClass = MODEL_MAP[class_name]\n",
    "    \n",
    "    # Re-instantiate the model\n",
    "    model = ModelClass(**kwargs)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f771b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_logits_and_llr(model: nn.Module, dataloader: DataLoader, llr_function: callable) -> pd.DataFrame: \n",
    "    records = []\n",
    "    \n",
    "    for batch in dataloader: \n",
    "        B = batch['query_y'].shape[0]\n",
    "        with torch.no_grad(): \n",
    "            logits = model(\n",
    "                context_x = batch['context_x'],\n",
    "                context_y = batch['context_y'],\n",
    "                query_x = batch['query_x'],\n",
    "            )\n",
    "            logits = logits.cpu().squeeze(-1).numpy()  # (B,)\n",
    "        query_y = batch['query_y'].cpu().numpy()  # (B,)\n",
    "\n",
    "        # Compute Bayes-optimal LLRs\n",
    "        task_params = batch['task_params']\n",
    "        task_params = {k: v.cpu().numpy() for k, v in task_params.items()}\n",
    "        llrs = llr_function(batch['query_x'].cpu().numpy(), **task_params)  # (B,)\n",
    "        for i in range(B):\n",
    "            records.append({\n",
    "                'model_logit': logits[i],\n",
    "                'bayes_llr': llrs[i],\n",
    "                'true_label': query_y[i],\n",
    "            })\n",
    "    return pd.DataFrame.from_records(records)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9dd28",
   "metadata": {},
   "source": [
    "### Logit vs LLR Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1512c2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = load_model_from_checkpoint('checkpoints/task_A_regular/ICLTransformer_seed0.pt', device=train_cfg.device)\n",
    "model_B = load_model_from_checkpoint('checkpoints/task_B_regular/ICLTransformer_seed0.pt', device=train_cfg.device)\n",
    "\n",
    "logging.info('Extracting Task A Data...')\n",
    "df_A = extract_logits_and_llr(model_A, val_loader_A, task_A_llr)\n",
    "logging.info('Extracting Task B Data...')\n",
    "df_B = extract_logits_and_llr(model_B, val_loader_B, task_B_llr)\n",
    "\n",
    "def analyze_and_plot_logits_regression(df, task_name, ax):\n",
    "    # Metrics\n",
    "    r_p, _ = pearsonr(df['bayes_llr'], df['model_logit'])\n",
    "    rho_s, _ = spearmanr(df['bayes_llr'], df['model_logit'])\n",
    "    \n",
    "    # We downsample for scatter plot clarity if N is huge (e.g. > 2000 points)\n",
    "    plot_df = df.sample(2000) if len(df) > 2000 else df\n",
    "    \n",
    "    sns.regplot(\n",
    "        data=plot_df, \n",
    "        x='bayes_llr', \n",
    "        y='model_logit', \n",
    "        ax=ax, \n",
    "        scatter_kws={'alpha': 0.3, 's': 10}, \n",
    "        line_kws={'color': 'red'}\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'{task_name}\\nPearson $r={r_p:.3f}$ | Spearman $\\\\rho={rho_s:.3f}$')\n",
    "    ax.set_xlabel('True Analytical LLR')\n",
    "    ax.set_ylabel('Transformer Logit')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    logging.info(f'--- {task_name} ---')\n",
    "    logging.info(f'Pearson r: {r_p:.4f}')\n",
    "    logging.info(f'Spearman rho: {rho_s:.4f}')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "analyze_and_plot_logits_regression(df_A, 'Task A: Shifted Mean (Linear)', axes[0])\n",
    "analyze_and_plot_logits_regression(df_B, 'Task B: Variance (Quadratic)', axes[1])\n",
    "plt.tight_layout()\n",
    "plt.savefig('analysis_out/logits_regression_A_B.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f8af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_OOD = load_model_from_checkpoint('checkpoints/task_A_OOD/ICLTransformer_seed0.pt', device=train_cfg.device)\n",
    "\n",
    "logging.info('Extracting OOD Logits for Task A')\n",
    "df_ood = extract_logits_and_llr(model_A, val_loader_A_OOD, task_A_llr)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "analyze_and_plot_logits_regression(df_ood, fr'Task A (OOD): $\\sigma_k={data_cfg.sigma_k_ood}$', plt.gca())\n",
    "plt.savefig('analysis_out/logits_regression_A_OOD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028899f",
   "metadata": {},
   "source": [
    "## PART III: Mechanistic Interprability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b1b2d",
   "metadata": {},
   "source": [
    "### Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe68d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "\n",
    "def run_logit_lens(model, val_loader, task_type, num_batches=100):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Register Hooks to capture layer outputs\n",
    "    layer_outputs = {}\n",
    "    def hook_fn(name):\n",
    "        def fn(module, input, output):\n",
    "            # output shape: [Batch, SeqLen, D]\n",
    "            # Capture the Query token (last position)\n",
    "            query_repr = output[:, -1, :]\n",
    "            layer_outputs[name] = query_repr.detach()\n",
    "        return fn\n",
    "    hooks = []\n",
    "    # Hook output of each Transformer Layer\n",
    "    for i, layer in enumerate(model.transformer.layers):\n",
    "        h = layer.register_forward_hook(hook_fn(f'Layer {i + 1}'))\n",
    "        hooks.append(h)\n",
    "\n",
    "    all_results = []\n",
    "    loader_iter = iter(val_loader)\n",
    "\n",
    "    logging.info(f'Logit Lens ({task_type}): Running {num_batches} batches')\n",
    "\n",
    "    try:\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Batch Fetching\n",
    "            try:\n",
    "                batch = next(loader_iter)\n",
    "            except StopIteration:\n",
    "                loader_iter = iter(val_loader)\n",
    "                batch = next(loader_iter)\n",
    "\n",
    "            # Move Inputs\n",
    "            ctx_x = batch['context_x'].to(device)\n",
    "            ctx_y = batch['context_y'].to(device)\n",
    "            qry_x = batch['query_x'].to(device)\n",
    "\n",
    "            # Forward Pass (trigger hooks)\n",
    "            with torch.no_grad():\n",
    "                _ = model(ctx_x, ctx_y, qry_x)\n",
    "\n",
    "            # Compute True LLR\n",
    "            if task_type == 'A':\n",
    "                p = batch['task_params']\n",
    "                mu = p['mu'].to(device)\n",
    "                k = p['k'].to(device)\n",
    "                # Vectorized LLR A: 2 * mu^T (x - k)\n",
    "                centered = qry_x - k\n",
    "                llr = 2 * (mu * centered).sum(dim=1)\n",
    "            else:\n",
    "                # Task B: Use label as proxy (0 vs 1)\n",
    "                llr = batch['query_y'].to(device).float()\n",
    "\n",
    "            llr = llr.cpu().numpy()\n",
    "\n",
    "            # Virtual Logits\n",
    "            # Reconstruct Layer 0 (Input Embeddings) manually\n",
    "            with torch.no_grad():\n",
    "                if hasattr(model, 'y_proj'):\n",
    "                    # Task A/B model\n",
    "                    _ = model.x_proj(ctx_x) + model.y_proj(\n",
    "                        ctx_y.unsqueeze(-1).float()\n",
    "                    )\n",
    "                else:\n",
    "                    # Ablation models\n",
    "                    _ = model.x_proj(ctx_x)\n",
    "\n",
    "                q_emb = model.query_proj(qry_x).unsqueeze(1)\n",
    "                layer_outputs['Layer 0 (Input)'] = q_emb.squeeze(1)\n",
    "\n",
    "            layer_names = ['Layer 0 (Input)', 'Layer 1', 'Layer 2']\n",
    "\n",
    "            for name in layer_names:\n",
    "                if name in layer_outputs:\n",
    "                    repr_vector = layer_outputs[name]  # [B, D]\n",
    "\n",
    "                    # Decode using the Final Head\n",
    "                    virtual_logit = model.head(repr_vector)\n",
    "                    virtual_logit = virtual_logit.cpu().detach().numpy().flatten()\n",
    "\n",
    "                    # Calculate Correlations\n",
    "                    r, _ = pearsonr(llr, virtual_logit)\n",
    "                    rho, _ = spearmanr(llr, virtual_logit)\n",
    "\n",
    "                    # Store for DataFrame\n",
    "                    all_results.append({\n",
    "                        'Layer': name,\n",
    "                        'Metric': 'Pearson',\n",
    "                        'Value': r,\n",
    "                        'Batch': batch_idx\n",
    "                    })\n",
    "                    all_results.append({\n",
    "                        'Layer': name,\n",
    "                        'Metric': 'Spearman',\n",
    "                        'Value': rho,\n",
    "                        'Batch': batch_idx\n",
    "                    })\n",
    "\n",
    "    finally:\n",
    "        # Cleanup hooks immediately\n",
    "        for h in hooks:\n",
    "            h.remove()\n",
    "\n",
    "    if all_results:\n",
    "        df = pd.DataFrame(all_results)\n",
    "\n",
    "        # Print text summary\n",
    "        logging.info('\\nMean Correlations:')\n",
    "        logging.info(df.groupby(['Layer', 'Metric'])['Value'].mean())\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x='Layer',\n",
    "            y='Value',\n",
    "            hue='Metric',\n",
    "            palette='Blues_d',\n",
    "            errorbar=('ci', 95),\n",
    "            capsize=0.1\n",
    "        )\n",
    "\n",
    "        plt.title(f'Logit Lens: When is the decision made?')\n",
    "        plt.ylabel('Correlation with True LLR')\n",
    "        plt.ylim(-0.2, 1.1)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        save_path = f'analysis_out/logit_lens_{task_type}.png'\n",
    "        plt.savefig(save_path)\n",
    "        print(f'Saved plot to {save_path}')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "run_logit_lens(model_A, val_loader_A, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798662c6",
   "metadata": {},
   "source": [
    "### Kernel Regression Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kernel_regression_comparison(\n",
    "    model, val_loader, task_type='A', num_batches=20\n",
    "):\n",
    "    \"\"\"\n",
    "    Compares the Transformer's output against a hard-coded Nadaraya-Watson\n",
    "    Kernel Regression (Soft Nearest Neighbor) estimator.\n",
    "    \"\"\"\n",
    "    logging.info(f'Kernel Regression ({task_type}): Running {num_batches} batches')\n",
    "    \n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Storage for aggregation\n",
    "    all_nn_logits = []\n",
    "    all_algo_outputs = []\n",
    "\n",
    "    # Determine number of heads for scaling\n",
    "    try:\n",
    "        layer0 = model.transformer.layers[0]\n",
    "        if hasattr(layer0, 'self_attn'):\n",
    "            n_heads = layer0.self_attn.num_heads\n",
    "        elif hasattr(layer0, 'attn'):\n",
    "            n_heads = layer0.attn.num_heads\n",
    "        else:\n",
    "            n_heads = 4  # Fallback\n",
    "    except AttributeError:\n",
    "        n_heads = 4  # Fallback\n",
    "        \n",
    "    d_head = model.d_model // n_heads\n",
    "    scale = 1.0 / np.sqrt(d_head)\n",
    "\n",
    "    loader_iter = iter(val_loader)\n",
    "    try:\n",
    "        for _ in range(num_batches):\n",
    "            # Batch Fetching\n",
    "            try:\n",
    "                batch = next(loader_iter)\n",
    "            except StopIteration:\n",
    "                loader_iter = iter(val_loader)\n",
    "                batch = next(loader_iter)\n",
    "\n",
    "            # Move to device\n",
    "            xc = batch['context_x'].to(device)  # [B, N, D]\n",
    "            yc = batch['context_y'].to(device)  # [B, N]\n",
    "            xq = batch['query_x'].to(device)  # [B, D]\n",
    "            \n",
    "            # Run transformer to get logits\n",
    "            with torch.no_grad():\n",
    "                logits = model(xc, yc, xq).cpu().numpy().flatten()\n",
    "                all_nn_logits.append(logits)\n",
    "                \n",
    "            # Run the symbolic algorithm (Kernel Regression)\n",
    "            # Hypothesis: Prediction = Sum( Softmax(q @ k.T / sqrt(d)) * y )\n",
    "            with torch.no_grad():\n",
    "                # Compute Dot Product Similarities (The Kernel)\n",
    "                # [B, 1, D] @ [B, D, N] -> [B, 1, N]\n",
    "                xq_uns = xq.unsqueeze(1)\n",
    "                xc_T = xc.transpose(1, 2)\n",
    "                \n",
    "                # We use raw dot product as a proxy for the learned kernel\n",
    "                raw_scores = torch.bmm(xq_uns, xc_T).squeeze(1) * scale  # [B, N]\n",
    "                \n",
    "                # Softmax (The Attention Mechanism)\n",
    "                weights = F.softmax(raw_scores, dim=-1)  # [B, N]\n",
    "                \n",
    "                # Weighted Sum of Labels (The Value Aggregation)\n",
    "                # Convert 0/1 labels to -1/+1 polarity for aggregation\n",
    "                y_polar = (2 * yc - 1).float()\n",
    "                \n",
    "                # Algorithm Output\n",
    "                algo_out = (weights * y_polar).sum(dim=-1).cpu().numpy()\n",
    "                all_algo_outputs.append(algo_out)\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging.error(f'Error during extraction loop: {e}')\n",
    "        return\n",
    "\n",
    "    # Aggregate and compute correlation\n",
    "    nn_logits_flat = np.concatenate(all_nn_logits)\n",
    "    algo_outputs_flat = np.concatenate(all_algo_outputs)\n",
    "    corr = np.corrcoef(nn_logits_flat, algo_outputs_flat)[0, 1]\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    # Downsample for plotting if we have too many points (e.g., > 2000)\n",
    "    if len(nn_logits_flat) > 2000:\n",
    "        indices = np.random.choice(len(nn_logits_flat), 2000, replace=False)\n",
    "        plot_x = algo_outputs_flat[indices]\n",
    "        plot_y = nn_logits_flat[indices]\n",
    "    else:\n",
    "        plot_x = algo_outputs_flat\n",
    "        plot_y = nn_logits_flat\n",
    "    plt.scatter(plot_x, plot_y, alpha=0.3, s=15, c='purple', edgecolors='none')\n",
    "    if len(plot_x) > 1:\n",
    "        m, b = np.polyfit(plot_x, plot_y, 1)\n",
    "        plt.plot(\n",
    "            plot_x, m * plot_x + b, \n",
    "            'k--', lw=1.5, \n",
    "            label=f'Linear Fit'\n",
    "        )\n",
    "    plt.title(\n",
    "        f'Transformer vs. Kernel Regression (R={corr:.4f})'\n",
    "    )\n",
    "    plt.xlabel(r'Symbolic Output: $\\sum \\text{softmax}(x_q^\\top x_i) \\cdot y_i$')\n",
    "    plt.ylabel('Transformer Logit')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    save_path = f'analysis_out/kernel_regression_{task_type}.png'\n",
    "    plt.savefig(save_path)\n",
    "    logging.info(f'Extraction Correlation: {corr:.4f}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "extract_kernel_regression_comparison(model_A, val_loader_A, 'A', num_batches=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e457aabf",
   "metadata": {},
   "source": [
    "### OV-Circuit Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86492116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ov_circuit_alignment(model, task_type='A'):\n",
    "    \"\"\"\n",
    "    Analyzes the alignment between the OV Circuit (W_O * W_V) and the \n",
    "    Input/Output embeddings.\n",
    "    \"\"\"\n",
    "    logging.info(f'OV Circuit Alignment Analysis ({task_type})')\n",
    "    \n",
    "    model.eval()\n",
    "    # Get the static vectors\n",
    "    if not hasattr(model, 'y_proj'):\n",
    "        logging.warning('Model has no y_proj; skipping.')\n",
    "        return\n",
    "\n",
    "    # Move everything to CPU for analysis to avoid device mismatches\n",
    "    # The \"Class 1\" Input Vector\n",
    "    y_in = model.y_proj.weight.detach().cpu().squeeze().t() \n",
    "    y_in = F.normalize(y_in, dim=0)\n",
    "    # The \"Class 1\" Output Vector\n",
    "    logit_out = model.head.weight.detach().cpu().squeeze()\n",
    "    logit_out = F.normalize(logit_out, dim=0)\n",
    "    \n",
    "    # Iterate Through All Heads\n",
    "    # We assume standard PyTorch implementation logic here\n",
    "    n_layers = len(model.transformer.layers)\n",
    "    n_heads = model.transformer.layers[0].self_attn.num_heads\n",
    "    d_model = model.d_model\n",
    "    head_dim = d_model // n_heads\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for l in range(n_layers):\n",
    "        # Get Attention Layer Weights\n",
    "        attn = model.transformer.layers[l].self_attn\n",
    "        \n",
    "        # in_proj_weight is [3*D, D] -> [Q | K | V]\n",
    "        # We need V (index 2)\n",
    "        qkv = attn.in_proj_weight.detach().cpu()\n",
    "        w_v_all = qkv[2*d_model : 3*d_model, :] # [D, D]\n",
    "        w_o_all = attn.out_proj.weight.detach().cpu() # [D, D]\n",
    "        \n",
    "        for h in range(n_heads):\n",
    "            # Slice V and O for this specific head\n",
    "            row_start = h * head_dim\n",
    "            row_end = (h+1) * head_dim\n",
    "            # W_V_h: [Head_Dim, D_Model]\n",
    "            w_v_h = w_v_all[row_start:row_end, :]\n",
    "            # W_O_h: [D_Model, Head_Dim]\n",
    "            w_o_h = w_o_all[:, row_start:row_end]\n",
    "            # Compute the OV Circuit (W_O * W_V)\n",
    "            # This matrix describes: \"If I attend to vector x, what do I write to the residual stream?\"\n",
    "            w_ov_h = torch.matmul(w_o_h, w_v_h) # [D, D]\n",
    "            # Push the Label Vector through the Circuit\n",
    "            # \"If I attend to a token that IS the label, what do I write?\"\n",
    "            v_written = torch.matmul(w_ov_h, y_in)\n",
    "            # Check Alignment with the Logit Vector\n",
    "            # +1.0 = Perfect Copying (Induction)\n",
    "            # -1.0 = Perfect Suppression (Anti-Induction)\n",
    "            alignment = F.cosine_similarity(v_written, logit_out, dim=0).item()\n",
    "            results.append({\n",
    "                'Layer': l,\n",
    "                'Head': h,\n",
    "                'Alignment': alignment\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    pivot = df.pivot(index='Layer', columns='Head', values='Alignment')\n",
    "    logging.info(f'Flattened OV table: {pivot}')\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(pivot, annot=True, cmap='RdBu_r', center=0, fmt='.2f')\n",
    "    plt.title(f'OV-Circuit Alignment ({task_type})\\n(Does Head map Labels $\\\\to$ Logits?)')\n",
    "    plt.ylabel('Layer')\n",
    "    plt.xlabel('Head')\n",
    "    plt.tight_layout()\n",
    "    save_path = f'analysis_out/ov_circuit_alignment_{task_type}.png'\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4133b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = load_model_from_checkpoint('checkpoints/task_A_regular/ICLTransformer_seed0.pt', device=train_cfg.device)\n",
    "analyze_ov_circuit_alignment(model_A, 'A')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "implicit-likelihood-ratio-transformer (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
